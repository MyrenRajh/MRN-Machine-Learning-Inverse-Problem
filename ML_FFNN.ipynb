{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import torch as to\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import torch.utils.data as to_data\n",
    "import datetime as datetime\n",
    "from torch.utils.tensorboard import SummaryWriter as sumwriter\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Specify hardware for ML training (GPU default)\n",
    "device = \"cuda\" if to.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly generate list of strings for frequency numbers and ratios\n",
    "def freq_name(no_freq, include_freq=True, include_ratio=True):\n",
    "    \"\"\"\n",
    "    Creates an ordered list of string from inputted parameters:\n",
    "\n",
    "    no_freq = (int) number of desired frequencies\n",
    "    include_freq = (bool) include the individual frequencies or not (default True)\n",
    "    include_ratio = (bool) include the non-trivial ratios between frequencies or not (default True)\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    if include_freq:\n",
    "        for i in range(no_freq):\n",
    "            names.append('f'+str(i+1))\n",
    "    if include_ratio:\n",
    "        for i in range(no_freq):\n",
    "            for j in range(i):\n",
    "                names.append('f'+str(i+1)+'/f'+str(j+1))\n",
    "    return names\n",
    "\n",
    "def get_modecols(mode_num, divs=8):\n",
    "    names = []\n",
    "    for i in range(81):\n",
    "        names.append('m'+str(mode_num)+'_'+str(i+1))\n",
    "    names = np.array(names).reshape((9,9))\n",
    "    it = int(8/divs)\n",
    "    return list(names[::it, ::it].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch dataset class for data batching during training\n",
    "# class FFNN_data(to_data.Dataset):\n",
    "#     def __init__(self, scaled_dataframe, X_names, Y_names):\n",
    "#         self.len = len(scaled_dataframe)\n",
    "#         self.X = to.from_numpy(scaled_dataframe[X_names].to_numpy().astype('float32')).to(device)\n",
    "#         self.Y = to.from_numpy(scaled_dataframe[Y_names].to_numpy().astype('float32')).to(device)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "  \n",
    "#     def __getitem__(self, idx):\n",
    "#         X_idx = self.X[idx,:]\n",
    "#         Y_idx = self.Y[idx,:]\n",
    "#         return X_idx, Y_idx\n",
    "\n",
    "class FFNN_data(to_data.Dataset):\n",
    "    def __init__(self, X_array, Y_array):\n",
    "        self.len = X_array.shape[0]\n",
    "        self.X = to.from_numpy(X_array.astype('float32')).to(device)\n",
    "        self.Y = to.from_numpy(Y_array.astype('float32')).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        X_idx = self.X[idx,:]\n",
    "        Y_idx = self.Y[idx,:]\n",
    "        return X_idx, Y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates function that returns desired activation function\n",
    "def activation(activ_name):\n",
    "    if activ_name=='relu':\n",
    "        return to.nn.ReLU()\n",
    "    elif activ_name=='lrelu':\n",
    "        return to.nn.LeakyReLU()\n",
    "    elif activ_name=='prelu':\n",
    "        return to.nn.PReLU()\n",
    "    elif activ_name=='relu6':\n",
    "        return to.nn.ReLU6()\n",
    "    elif activ_name=='sigmoid':\n",
    "        return to.nn.Sigmoid()\n",
    "    elif activ_name=='tanh':\n",
    "        return to.nn.Tanh()\n",
    "    elif activ_name=='silu':\n",
    "        return to.nn.SiLU()\n",
    "    elif activ_name=='selu':\n",
    "        return to.nn.SELU()\n",
    "    elif activ_name=='celu':\n",
    "        return to.nn.CELU()\n",
    "    elif activ_name=='gelu':\n",
    "        return to.nn.GELU()\n",
    "    else:\n",
    "        return to.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_Network(to.nn.Module):\n",
    "    def __init__(self, num_X, num_Y, h_nodes, hactiv_type):\n",
    "        super(FF_Network, self).__init__()\n",
    "\n",
    "        self.feedfoward = []\n",
    "        self.feedfoward.append(to.nn.Linear(num_X, h_nodes[0]))\n",
    "        self.feedfoward.append(activation(hactiv_type))\n",
    "\n",
    "        for i in range(len(h_nodes)-1):\n",
    "            self.feedfoward.append(to.nn.Linear(h_nodes[i], h_nodes[i+1]))\n",
    "            self.feedfoward.append(activation(hactiv_type))\n",
    "\n",
    "        self.feedfoward.append(to.nn.Linear(h_nodes[-1], num_Y))\n",
    "\n",
    "        self.feedfoward = to.nn.Sequential(*self.feedfoward).to(device)\n",
    "        for i in self.feedfoward[::2]:\n",
    "            to.nn.init.kaiming_uniform_(i.weight)\n",
    "            to.nn.init.zeros_(i.bias)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.feedfoward(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    network,\n",
    "    train_dataloader,\n",
    "    loss_function, optimizer,\n",
    "    tb_writer, epoch_ind\n",
    "    ):\n",
    "\n",
    "    loss_list = []\n",
    "    MAPE_list = []\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        X, Y = data\n",
    "\n",
    "        if epoch_ind==0 and i==0:\n",
    "            tb_writer.add_graph(network, X, verbose=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictY = network(X)\n",
    "\n",
    "        loss = loss_function(predictY, Y)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        MAPE = to.mean(to.abs((Y - predictY) / Y)*100)\n",
    "        MAPE_list.append(MAPE.item())\n",
    "\n",
    "    \n",
    "    mean_loss = to.mean(to.tensor(loss_list, device=device)).item()\n",
    "    mean_MAPE = to.mean(to.tensor(MAPE_list, device=device)).item()\n",
    "\n",
    "    return mean_loss, mean_MAPE\n",
    "\n",
    "def valid_epoch(\n",
    "    network,\n",
    "    valid_dataloader,\n",
    "    loss_function\n",
    "    ):\n",
    "\n",
    "    loss_list = []\n",
    "    MAPE_list = []\n",
    "\n",
    "    for i, data in enumerate(valid_dataloader):\n",
    "        X, Y = data\n",
    "        predictY = network(X)\n",
    "\n",
    "        loss = loss_function(predictY, Y)\n",
    "        loss_list.append(loss.item())\n",
    " \n",
    "        MAPE = to.mean(to.abs((Y - predictY) / Y)*100)\n",
    "        MAPE_list.append(MAPE.item())\n",
    "    \n",
    "    mean_loss = to.mean(to.tensor(loss_list, device=device)).item()\n",
    "    mean_MAPE = to.mean(to.tensor(MAPE_list, device=device)).item()\n",
    "    return mean_loss, mean_MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_FFNN(\n",
    "    network,\n",
    "    train_dataloader, valid_dataloader,\n",
    "    loss_function, optimizer_type,\n",
    "    epochs, learn_rate\n",
    "    ):\n",
    "\n",
    "    if optimizer_type=='adam':\n",
    "        optimizer = to.optim.Adam(network.parameters(), lr=learn_rate)\n",
    "    else:\n",
    "        optimizer = to.optim.SGD(network.parameters(), lr=learn_rate)\n",
    "    \n",
    "    tb_writer = sumwriter('Current_ML_Results/Tensorboard/'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        network.train(True)\n",
    "        mloss, mMAPE = train_epoch(network, train_dataloader, loss_function, optimizer, tb_writer, i)\n",
    "\n",
    "        network.eval()\n",
    "        with to.no_grad():\n",
    "            vmloss, vmMAPE = valid_epoch(network, valid_dataloader, loss_function)\n",
    "        \n",
    "\n",
    "        print('-'*50)\n",
    "        print('Epoch {} / {}'.format(i+1,epochs))\n",
    "        print('-'*15)\n",
    "        print('Average Train Loss : {}'.format(mloss))\n",
    "        print('Average Validation Loss : {}'.format(vmloss))\n",
    "\n",
    "        tb_writer.add_scalars(\"Batch Mean Loss\",\n",
    "                            {\n",
    "                                'Train' : mloss,\n",
    "                                'Validation' : vmloss\n",
    "                            }, i+1)\n",
    "\n",
    "        # tb_writer.add_scalars(\"Batch MAPE\",\n",
    "        #                     {\n",
    "        #                         'Train' : mMAPE,\n",
    "        #                         'Validation' : vmMAPE\n",
    "        #                     }, i+1)\n",
    "\n",
    "    tb_writer.flush()\n",
    "    tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "import sklearn.preprocessing as sk_preproc\n",
    "data = pd.read_csv('Data Workspace/FS_TV.csv')\n",
    "num_freq = 8\n",
    "\n",
    "features =  freq_name(num_freq,1,1)\n",
    "labels = ['nu', 'a/b', 'a/h', 'b/h', 'Q2', 'Q3', 'Q4', 'c1/a', 'c1/b']\n",
    "\n",
    "train_split = 35000\n",
    "valid_split = 7500\n",
    "\n",
    "scaled_data = data[features+labels].copy()\n",
    "scalerX = sk_preproc.StandardScaler()\n",
    "scalerY = sk_preproc.StandardScaler()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = scaled_data[freq_name(num_freq,1,0)] * (1 + (np.random.randint(0,2,scaled_data[freq_name(num_freq,1,0)].shape)*2-1)*np.random.normal(5/100, 5/100,scaled_data[freq_name(num_freq,1,0)].shape))\n",
    "for x in range(num_freq):\n",
    "    y = x+1\n",
    "    for k in range(y-1):\n",
    "        l = k+1\n",
    "        ratio_str = 'f'+str(y)+'/f'+str(l)\n",
    "        scaled_data[ratio_str] = scaled_data['f'+str(y)] /data['f'+str(l)]\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "scalerX.fit(scaled_data[features])\n",
    "scalerY.fit(scaled_data[labels])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "train_set, valid_set = to_data.random_split(scaled_data, [train_split, valid_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# Parameters\n",
    "num_X = len(features)\n",
    "num_Y = len(labels)\n",
    "h_nodes = [60,55,50,45,40,35,30,25,20,15]\n",
    "hactiv = 'silu'\n",
    "\n",
    "batch_size_train = 100\n",
    "batch_size_valid = 2000\n",
    "\n",
    "epochs = 150\n",
    "learn_rate = 1e-3\n",
    "\n",
    "# Optim Selections\n",
    "loss_function = to.nn.SmoothL1Loss()\n",
    "optimizer_type = 'adam'\n",
    "\n",
    "# Data loaders\n",
    "train_loader = to.utils.data.DataLoader(train_set, batch_size=batch_size_train, shuffle=True)\n",
    "valid_loader = to.utils.data.DataLoader(valid_set, batch_size=batch_size_valid, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = FF_Network(num_X, num_Y, h_nodes, hactiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.1507401317358017\n",
      "Average Validation Loss : 0.08528842031955719\n",
      "--------------------------------------------------\n",
      "Epoch 2 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.07923229783773422\n",
      "Average Validation Loss : 0.076496921479702\n",
      "--------------------------------------------------\n",
      "Epoch 3 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.06834258884191513\n",
      "Average Validation Loss : 0.061186548322439194\n",
      "--------------------------------------------------\n",
      "Epoch 4 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.05346061289310455\n",
      "Average Validation Loss : 0.050131723284721375\n",
      "--------------------------------------------------\n",
      "Epoch 5 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.04774409160017967\n",
      "Average Validation Loss : 0.04600193351507187\n",
      "--------------------------------------------------\n",
      "Epoch 6 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.04477812722325325\n",
      "Average Validation Loss : 0.04680104926228523\n",
      "--------------------------------------------------\n",
      "Epoch 7 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.042580101639032364\n",
      "Average Validation Loss : 0.04197399318218231\n",
      "--------------------------------------------------\n",
      "Epoch 8 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03997250646352768\n",
      "Average Validation Loss : 0.040368035435676575\n",
      "--------------------------------------------------\n",
      "Epoch 9 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03876897320151329\n",
      "Average Validation Loss : 0.03735101968050003\n",
      "--------------------------------------------------\n",
      "Epoch 10 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.0372929610311985\n",
      "Average Validation Loss : 0.036963868886232376\n",
      "--------------------------------------------------\n",
      "Epoch 11 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03571295738220215\n",
      "Average Validation Loss : 0.036638256162405014\n",
      "--------------------------------------------------\n",
      "Epoch 12 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.035252634435892105\n",
      "Average Validation Loss : 0.0345819890499115\n",
      "--------------------------------------------------\n",
      "Epoch 13 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.033437617123126984\n",
      "Average Validation Loss : 0.033014655113220215\n",
      "--------------------------------------------------\n",
      "Epoch 14 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03242681175470352\n",
      "Average Validation Loss : 0.031325917690992355\n",
      "--------------------------------------------------\n",
      "Epoch 15 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03135203570127487\n",
      "Average Validation Loss : 0.03073125146329403\n",
      "--------------------------------------------------\n",
      "Epoch 16 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.03090501017868519\n",
      "Average Validation Loss : 0.03258582204580307\n",
      "--------------------------------------------------\n",
      "Epoch 17 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02999778650701046\n",
      "Average Validation Loss : 0.03056146949529648\n",
      "--------------------------------------------------\n",
      "Epoch 18 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.030007634311914444\n",
      "Average Validation Loss : 0.031047550961375237\n",
      "--------------------------------------------------\n",
      "Epoch 19 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.029410311952233315\n",
      "Average Validation Loss : 0.03093673661351204\n",
      "--------------------------------------------------\n",
      "Epoch 20 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02846958115696907\n",
      "Average Validation Loss : 0.029256759211421013\n",
      "--------------------------------------------------\n",
      "Epoch 21 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.028279392048716545\n",
      "Average Validation Loss : 0.027043381705880165\n",
      "--------------------------------------------------\n",
      "Epoch 22 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.027728350833058357\n",
      "Average Validation Loss : 0.029127491638064384\n",
      "--------------------------------------------------\n",
      "Epoch 23 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02747093141078949\n",
      "Average Validation Loss : 0.026769887655973434\n",
      "--------------------------------------------------\n",
      "Epoch 24 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.027351437136530876\n",
      "Average Validation Loss : 0.027947481721639633\n",
      "--------------------------------------------------\n",
      "Epoch 25 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.027029085904359818\n",
      "Average Validation Loss : 0.027898021042346954\n",
      "--------------------------------------------------\n",
      "Epoch 26 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.027069928124547005\n",
      "Average Validation Loss : 0.027911867946386337\n",
      "--------------------------------------------------\n",
      "Epoch 27 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02665751613676548\n",
      "Average Validation Loss : 0.02828262560069561\n",
      "--------------------------------------------------\n",
      "Epoch 28 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.026645774021744728\n",
      "Average Validation Loss : 0.026846155524253845\n",
      "--------------------------------------------------\n",
      "Epoch 29 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02613549306988716\n",
      "Average Validation Loss : 0.027014270424842834\n",
      "--------------------------------------------------\n",
      "Epoch 30 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.026262249797582626\n",
      "Average Validation Loss : 0.026334641501307487\n",
      "--------------------------------------------------\n",
      "Epoch 31 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.026282664388418198\n",
      "Average Validation Loss : 0.02678142488002777\n",
      "--------------------------------------------------\n",
      "Epoch 32 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025337453931570053\n",
      "Average Validation Loss : 0.025414444506168365\n",
      "--------------------------------------------------\n",
      "Epoch 33 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025397859513759613\n",
      "Average Validation Loss : 0.025508301332592964\n",
      "--------------------------------------------------\n",
      "Epoch 34 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025301015004515648\n",
      "Average Validation Loss : 0.025490354746580124\n",
      "--------------------------------------------------\n",
      "Epoch 35 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025208132341504097\n",
      "Average Validation Loss : 0.0249020978808403\n",
      "--------------------------------------------------\n",
      "Epoch 36 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025296878069639206\n",
      "Average Validation Loss : 0.025907345116138458\n",
      "--------------------------------------------------\n",
      "Epoch 37 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.025047389790415764\n",
      "Average Validation Loss : 0.02663605660200119\n",
      "--------------------------------------------------\n",
      "Epoch 38 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.024896986782550812\n",
      "Average Validation Loss : 0.02449694275856018\n",
      "--------------------------------------------------\n",
      "Epoch 39 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02452796883881092\n",
      "Average Validation Loss : 0.02720106765627861\n",
      "--------------------------------------------------\n",
      "Epoch 40 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.024440879002213478\n",
      "Average Validation Loss : 0.024025648832321167\n",
      "--------------------------------------------------\n",
      "Epoch 41 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02456657402217388\n",
      "Average Validation Loss : 0.027716923505067825\n",
      "--------------------------------------------------\n",
      "Epoch 42 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.024362698197364807\n",
      "Average Validation Loss : 0.02646101452410221\n",
      "--------------------------------------------------\n",
      "Epoch 43 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.024165978655219078\n",
      "Average Validation Loss : 0.02514273300766945\n",
      "--------------------------------------------------\n",
      "Epoch 44 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.024056827649474144\n",
      "Average Validation Loss : 0.023845018818974495\n",
      "--------------------------------------------------\n",
      "Epoch 45 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02403631992638111\n",
      "Average Validation Loss : 0.0239788219332695\n",
      "--------------------------------------------------\n",
      "Epoch 46 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.0235797930508852\n",
      "Average Validation Loss : 0.023876704275608063\n",
      "--------------------------------------------------\n",
      "Epoch 47 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.023354850709438324\n",
      "Average Validation Loss : 0.023365521803498268\n",
      "--------------------------------------------------\n",
      "Epoch 48 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02293708734214306\n",
      "Average Validation Loss : 0.024900641292333603\n",
      "--------------------------------------------------\n",
      "Epoch 49 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.023526061326265335\n",
      "Average Validation Loss : 0.024582313373684883\n",
      "--------------------------------------------------\n",
      "Epoch 50 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.023151103407144547\n",
      "Average Validation Loss : 0.023266669362783432\n",
      "--------------------------------------------------\n",
      "Epoch 51 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.022819068282842636\n",
      "Average Validation Loss : 0.026382802054286003\n",
      "--------------------------------------------------\n",
      "Epoch 52 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.022809110581874847\n",
      "Average Validation Loss : 0.024201951920986176\n",
      "--------------------------------------------------\n",
      "Epoch 53 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02283526584506035\n",
      "Average Validation Loss : 0.024333085864782333\n",
      "--------------------------------------------------\n",
      "Epoch 54 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.022137973457574844\n",
      "Average Validation Loss : 0.02298007719218731\n",
      "--------------------------------------------------\n",
      "Epoch 55 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02242388017475605\n",
      "Average Validation Loss : 0.022270336747169495\n",
      "--------------------------------------------------\n",
      "Epoch 56 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.022332029417157173\n",
      "Average Validation Loss : 0.02440311387181282\n",
      "--------------------------------------------------\n",
      "Epoch 57 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02237861230969429\n",
      "Average Validation Loss : 0.02236887440085411\n",
      "--------------------------------------------------\n",
      "Epoch 58 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02181655541062355\n",
      "Average Validation Loss : 0.0218194629997015\n",
      "--------------------------------------------------\n",
      "Epoch 59 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.021761853247880936\n",
      "Average Validation Loss : 0.022941172122955322\n",
      "--------------------------------------------------\n",
      "Epoch 60 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02145031839609146\n",
      "Average Validation Loss : 0.022978752851486206\n",
      "--------------------------------------------------\n",
      "Epoch 61 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.021740838885307312\n",
      "Average Validation Loss : 0.02127121016383171\n",
      "--------------------------------------------------\n",
      "Epoch 62 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.0209516528993845\n",
      "Average Validation Loss : 0.02295447140932083\n",
      "--------------------------------------------------\n",
      "Epoch 63 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.021231310442090034\n",
      "Average Validation Loss : 0.022434651851654053\n",
      "--------------------------------------------------\n",
      "Epoch 64 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02074483595788479\n",
      "Average Validation Loss : 0.022034142166376114\n",
      "--------------------------------------------------\n",
      "Epoch 65 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.020513728260993958\n",
      "Average Validation Loss : 0.021926457062363625\n",
      "--------------------------------------------------\n",
      "Epoch 66 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.02108312025666237\n",
      "Average Validation Loss : 0.022716760635375977\n",
      "--------------------------------------------------\n",
      "Epoch 67 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.020318366587162018\n",
      "Average Validation Loss : 0.02021189033985138\n",
      "--------------------------------------------------\n",
      "Epoch 68 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.020347455516457558\n",
      "Average Validation Loss : 0.023375656455755234\n",
      "--------------------------------------------------\n",
      "Epoch 69 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.020519541576504707\n",
      "Average Validation Loss : 0.022302020341157913\n",
      "--------------------------------------------------\n",
      "Epoch 70 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.020192384719848633\n",
      "Average Validation Loss : 0.02215491607785225\n",
      "--------------------------------------------------\n",
      "Epoch 71 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01985759101808071\n",
      "Average Validation Loss : 0.021357769146561623\n",
      "--------------------------------------------------\n",
      "Epoch 72 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019966868683695793\n",
      "Average Validation Loss : 0.0208219476044178\n",
      "--------------------------------------------------\n",
      "Epoch 73 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01940970867872238\n",
      "Average Validation Loss : 0.02082611806690693\n",
      "--------------------------------------------------\n",
      "Epoch 74 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019731031730771065\n",
      "Average Validation Loss : 0.021711617708206177\n",
      "--------------------------------------------------\n",
      "Epoch 75 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019534053280949593\n",
      "Average Validation Loss : 0.02002466470003128\n",
      "--------------------------------------------------\n",
      "Epoch 76 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019141362980008125\n",
      "Average Validation Loss : 0.020016217604279518\n",
      "--------------------------------------------------\n",
      "Epoch 77 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019136929884552956\n",
      "Average Validation Loss : 0.020905574783682823\n",
      "--------------------------------------------------\n",
      "Epoch 78 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019520984962582588\n",
      "Average Validation Loss : 0.020004987716674805\n",
      "--------------------------------------------------\n",
      "Epoch 79 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019277270883321762\n",
      "Average Validation Loss : 0.023985648527741432\n",
      "--------------------------------------------------\n",
      "Epoch 80 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019041912630200386\n",
      "Average Validation Loss : 0.02113773301243782\n",
      "--------------------------------------------------\n",
      "Epoch 81 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018941137939691544\n",
      "Average Validation Loss : 0.019732220098376274\n",
      "--------------------------------------------------\n",
      "Epoch 82 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.019044358283281326\n",
      "Average Validation Loss : 0.018502701073884964\n",
      "--------------------------------------------------\n",
      "Epoch 83 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01861497014760971\n",
      "Average Validation Loss : 0.019004162400960922\n",
      "--------------------------------------------------\n",
      "Epoch 84 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018965648487210274\n",
      "Average Validation Loss : 0.01949615404009819\n",
      "--------------------------------------------------\n",
      "Epoch 85 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018403207883238792\n",
      "Average Validation Loss : 0.01848043128848076\n",
      "--------------------------------------------------\n",
      "Epoch 86 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018228653818368912\n",
      "Average Validation Loss : 0.018327271565794945\n",
      "--------------------------------------------------\n",
      "Epoch 87 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018460959196090698\n",
      "Average Validation Loss : 0.019565032795071602\n",
      "--------------------------------------------------\n",
      "Epoch 88 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.0183468796312809\n",
      "Average Validation Loss : 0.021537987515330315\n",
      "--------------------------------------------------\n",
      "Epoch 89 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018854135647416115\n",
      "Average Validation Loss : 0.017740828916430473\n",
      "--------------------------------------------------\n",
      "Epoch 90 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01818251982331276\n",
      "Average Validation Loss : 0.019648652523756027\n",
      "--------------------------------------------------\n",
      "Epoch 91 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018622715026140213\n",
      "Average Validation Loss : 0.018996063619852066\n",
      "--------------------------------------------------\n",
      "Epoch 92 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018286967650055885\n",
      "Average Validation Loss : 0.01955452747642994\n",
      "--------------------------------------------------\n",
      "Epoch 93 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017948420718312263\n",
      "Average Validation Loss : 0.020756874233484268\n",
      "--------------------------------------------------\n",
      "Epoch 94 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018105924129486084\n",
      "Average Validation Loss : 0.020375430583953857\n",
      "--------------------------------------------------\n",
      "Epoch 95 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.018047161400318146\n",
      "Average Validation Loss : 0.01833217963576317\n",
      "--------------------------------------------------\n",
      "Epoch 96 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017857791855931282\n",
      "Average Validation Loss : 0.019017783924937248\n",
      "--------------------------------------------------\n",
      "Epoch 97 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01834915764629841\n",
      "Average Validation Loss : 0.022445064038038254\n",
      "--------------------------------------------------\n",
      "Epoch 98 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017942415550351143\n",
      "Average Validation Loss : 0.01884341984987259\n",
      "--------------------------------------------------\n",
      "Epoch 99 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017588794231414795\n",
      "Average Validation Loss : 0.018193410709500313\n",
      "--------------------------------------------------\n",
      "Epoch 100 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01770131289958954\n",
      "Average Validation Loss : 0.01952817663550377\n",
      "--------------------------------------------------\n",
      "Epoch 101 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017468713223934174\n",
      "Average Validation Loss : 0.019759612157940865\n",
      "--------------------------------------------------\n",
      "Epoch 102 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017642740160226822\n",
      "Average Validation Loss : 0.017900358885526657\n",
      "--------------------------------------------------\n",
      "Epoch 103 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01721036620438099\n",
      "Average Validation Loss : 0.018249090760946274\n",
      "--------------------------------------------------\n",
      "Epoch 104 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01770762726664543\n",
      "Average Validation Loss : 0.0178100373595953\n",
      "--------------------------------------------------\n",
      "Epoch 105 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017011579126119614\n",
      "Average Validation Loss : 0.017786966636776924\n",
      "--------------------------------------------------\n",
      "Epoch 106 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01710730977356434\n",
      "Average Validation Loss : 0.018231306225061417\n",
      "--------------------------------------------------\n",
      "Epoch 107 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017374111339449883\n",
      "Average Validation Loss : 0.01842888817191124\n",
      "--------------------------------------------------\n",
      "Epoch 108 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01658768579363823\n",
      "Average Validation Loss : 0.01710561290383339\n",
      "--------------------------------------------------\n",
      "Epoch 109 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017026705667376518\n",
      "Average Validation Loss : 0.017321757972240448\n",
      "--------------------------------------------------\n",
      "Epoch 110 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017873140051960945\n",
      "Average Validation Loss : 0.019115028902888298\n",
      "--------------------------------------------------\n",
      "Epoch 111 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.017148856073617935\n",
      "Average Validation Loss : 0.017336852848529816\n",
      "--------------------------------------------------\n",
      "Epoch 112 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016931144520640373\n",
      "Average Validation Loss : 0.01903967559337616\n",
      "--------------------------------------------------\n",
      "Epoch 113 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01754564233124256\n",
      "Average Validation Loss : 0.017386360093951225\n",
      "--------------------------------------------------\n",
      "Epoch 114 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016637960448861122\n",
      "Average Validation Loss : 0.018350455909967422\n",
      "--------------------------------------------------\n",
      "Epoch 115 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016675638034939766\n",
      "Average Validation Loss : 0.01863190531730652\n",
      "--------------------------------------------------\n",
      "Epoch 116 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016825687140226364\n",
      "Average Validation Loss : 0.01960165798664093\n",
      "--------------------------------------------------\n",
      "Epoch 117 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016491476446390152\n",
      "Average Validation Loss : 0.01732025109231472\n",
      "--------------------------------------------------\n",
      "Epoch 118 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01665051281452179\n",
      "Average Validation Loss : 0.0171089805662632\n",
      "--------------------------------------------------\n",
      "Epoch 119 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01701645739376545\n",
      "Average Validation Loss : 0.01951463706791401\n",
      "--------------------------------------------------\n",
      "Epoch 120 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016740577295422554\n",
      "Average Validation Loss : 0.016985731199383736\n",
      "--------------------------------------------------\n",
      "Epoch 121 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016325121745467186\n",
      "Average Validation Loss : 0.019418777897953987\n",
      "--------------------------------------------------\n",
      "Epoch 122 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016268447041511536\n",
      "Average Validation Loss : 0.01756470277905464\n",
      "--------------------------------------------------\n",
      "Epoch 123 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01643633469939232\n",
      "Average Validation Loss : 0.018047401681542397\n",
      "--------------------------------------------------\n",
      "Epoch 124 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016148442402482033\n",
      "Average Validation Loss : 0.01810498908162117\n",
      "--------------------------------------------------\n",
      "Epoch 125 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016564134508371353\n",
      "Average Validation Loss : 0.01777038723230362\n",
      "--------------------------------------------------\n",
      "Epoch 126 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016272546723484993\n",
      "Average Validation Loss : 0.018857412040233612\n",
      "--------------------------------------------------\n",
      "Epoch 127 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01653885468840599\n",
      "Average Validation Loss : 0.01663014478981495\n",
      "--------------------------------------------------\n",
      "Epoch 128 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016431983560323715\n",
      "Average Validation Loss : 0.019037537276744843\n",
      "--------------------------------------------------\n",
      "Epoch 129 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016343291848897934\n",
      "Average Validation Loss : 0.01704064942896366\n",
      "--------------------------------------------------\n",
      "Epoch 130 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01623418554663658\n",
      "Average Validation Loss : 0.017143696546554565\n",
      "--------------------------------------------------\n",
      "Epoch 131 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01619018241763115\n",
      "Average Validation Loss : 0.017825189977884293\n",
      "--------------------------------------------------\n",
      "Epoch 132 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015905087813735008\n",
      "Average Validation Loss : 0.01680540293455124\n",
      "--------------------------------------------------\n",
      "Epoch 133 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016111982986330986\n",
      "Average Validation Loss : 0.01693299226462841\n",
      "--------------------------------------------------\n",
      "Epoch 134 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01635131426155567\n",
      "Average Validation Loss : 0.017293691635131836\n",
      "--------------------------------------------------\n",
      "Epoch 135 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01595723070204258\n",
      "Average Validation Loss : 0.01676321029663086\n",
      "--------------------------------------------------\n",
      "Epoch 136 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015974970534443855\n",
      "Average Validation Loss : 0.018278859555721283\n",
      "--------------------------------------------------\n",
      "Epoch 137 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016110286116600037\n",
      "Average Validation Loss : 0.016195207834243774\n",
      "--------------------------------------------------\n",
      "Epoch 138 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015636809170246124\n",
      "Average Validation Loss : 0.018697794526815414\n",
      "--------------------------------------------------\n",
      "Epoch 139 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016217730939388275\n",
      "Average Validation Loss : 0.016547849401831627\n",
      "--------------------------------------------------\n",
      "Epoch 140 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01579427905380726\n",
      "Average Validation Loss : 0.01724386215209961\n",
      "--------------------------------------------------\n",
      "Epoch 141 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015904702246189117\n",
      "Average Validation Loss : 0.018514854833483696\n",
      "--------------------------------------------------\n",
      "Epoch 142 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015780622139573097\n",
      "Average Validation Loss : 0.016255073249340057\n",
      "--------------------------------------------------\n",
      "Epoch 143 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015674380585551262\n",
      "Average Validation Loss : 0.017409710213541985\n",
      "--------------------------------------------------\n",
      "Epoch 144 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.016003098338842392\n",
      "Average Validation Loss : 0.016373049467802048\n",
      "--------------------------------------------------\n",
      "Epoch 145 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01537265907973051\n",
      "Average Validation Loss : 0.017279285937547684\n",
      "--------------------------------------------------\n",
      "Epoch 146 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01566322334110737\n",
      "Average Validation Loss : 0.017473310232162476\n",
      "--------------------------------------------------\n",
      "Epoch 147 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01629773899912834\n",
      "Average Validation Loss : 0.01688557118177414\n",
      "--------------------------------------------------\n",
      "Epoch 148 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015816835686564445\n",
      "Average Validation Loss : 0.016151010990142822\n",
      "--------------------------------------------------\n",
      "Epoch 149 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.015593749471008778\n",
      "Average Validation Loss : 0.0171137023717165\n",
      "--------------------------------------------------\n",
      "Epoch 150 / 150\n",
      "---------------\n",
      "Average Train Loss : 0.01565825566649437\n",
      "Average Validation Loss : 0.016456089913845062\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_FFNN(\n",
    "    model,\n",
    "    train_loader, valid_loader,\n",
    "    loss_function, optimizer_type,\n",
    "    epochs, learn_rate)\n",
    "\n",
    "to.save(model.state_dict(), 'Current_ML_Results/model.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(to.load('Current_ML_Results\\S_FFNN_final_model.state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict FS TV Data\n",
    "data = pd.read_csv('Data Workspace/FS_TV.csv')\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "FS_TV_X = X.to('cpu')\n",
    "FS_TV_Y = Y.to('cpu')\n",
    "FS_TV_predictY = predictY.to('cpu')\n",
    "\n",
    "FS_TV_error = abs_perc_error.to('cpu')\n",
    "FS_TV_error_mean = MAPE_per_dim.to('cpu')\n",
    "FS_TV_error_std = SDAPE_per_dim.to('cpu')\n",
    "\n",
    "###########################################\n",
    "# Predict FS Te Data\n",
    "data = pd.read_csv('Data Workspace/FS_Te.csv')\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "FS_Te_X = X.to('cpu')\n",
    "FS_Te_Y = Y.to('cpu')\n",
    "FS_Te_predictY = predictY.to('cpu')\n",
    "\n",
    "FS_Te_error = abs_perc_error.to('cpu')\n",
    "FS_Te_error_mean = MAPE_per_dim.to('cpu')\n",
    "FS_Te_error_std = SDAPE_per_dim.to('cpu')\n",
    "\n",
    "###########################################\n",
    "# Predict RS TV Data\n",
    "data = pd.read_csv('Data Workspace/RS_TV.csv')\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "RS_TV_X = X.to('cpu')\n",
    "RS_TV_Y = Y.to('cpu')\n",
    "RS_TV_predictY = predictY.to('cpu')\n",
    "\n",
    "RS_TV_error = abs_perc_error.to('cpu')\n",
    "RS_TV_error_mean = MAPE_per_dim.to('cpu')\n",
    "RS_TV_error_std = SDAPE_per_dim.to('cpu')\n",
    "\n",
    "###########################################\n",
    "# Predict RS Te Data\n",
    "data = pd.read_csv('Data Workspace/RS_Te.csv')\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "RS_Te_X = X.to('cpu')\n",
    "RS_Te_Y = Y.to('cpu')\n",
    "RS_Te_predictY = predictY.to('cpu')\n",
    "\n",
    "RS_Te_error = abs_perc_error.to('cpu')\n",
    "RS_Te_error_mean = MAPE_per_dim.to('cpu')\n",
    "RS_Te_error_std = SDAPE_per_dim.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_labels = [r'$\\nu$', r'$a/b$', r'$a/h$', r'$b/h$', r'$Q_2$', r'$Q_3$', r'$Q_4$', r'$c_1/a$', r'$c_1/b$']\n",
    "\n",
    "# Error Plot\n",
    "fig, ((ax1, ax3), (ax2, ax4)) = plt.subplots(2, 2, figsize=(16,8))\n",
    "ax1.errorbar(plot_labels, FS_TV_error_mean, FS_TV_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='green')\n",
    "ax2.errorbar(plot_labels, FS_Te_error_mean, FS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='red')\n",
    "\n",
    "ax3.errorbar(plot_labels, RS_TV_error_mean, RS_TV_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='mediumseagreen')\n",
    "ax4.errorbar(plot_labels, RS_Te_error_mean, RS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='tomato')\n",
    "\n",
    "ax1.set_ylim(-5,35)\n",
    "ax2.set_ylim(-5,35)\n",
    "ax3.set_ylim(-5,35)\n",
    "ax4.set_ylim(-5,35)\n",
    "\n",
    "ax1.set_ylabel('MAPE [%]')\n",
    "ax2.set_ylabel('MAPE [%]')\n",
    "ax3.set_ylabel('MAPE [%]')\n",
    "ax4.set_ylabel('MAPE [%]')\n",
    "\n",
    "ax1.set_xlabel('Plate Property')\n",
    "ax2.set_xlabel('Plate Property')\n",
    "ax3.set_xlabel('Plate Property')\n",
    "ax4.set_xlabel('Plate Property')\n",
    "\n",
    "ax1.set_title('FS - Train Validation Set ')\n",
    "ax2.set_title('FS - Test Set')\n",
    "ax3.set_title('RS - Train Validation Set')\n",
    "ax4.set_title('RS - Test Set')\n",
    "\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "ax4.grid()\n",
    "\n",
    "fig.suptitle('S-FFNN Absolute Percentage Error', fontsize=14)\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.35, top=0.925)\n",
    "\n",
    "plt.savefig('S_FFNN_error_plot.pdf',dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arr = to.stack((FS_TV_error_mean, FS_TV_error_std, FS_Te_error_mean, FS_Te_error_std, RS_TV_error_mean, RS_TV_error_std, RS_Te_error_mean, RS_Te_error_std ),axis=0)\n",
    "perf_df = pd.DataFrame(df_arr, columns=labels, index=['FS TV MAPE', 'FS TV SDAPE', 'FS Te MAPE', 'FS Te SDAPE', 'RS TV MAPE', 'RS TV SDAPE', 'RS Te MAPE', 'RS Te SDAPE',])\n",
    "perf_df.to_excel('performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nu</th>\n",
       "      <th>a/b</th>\n",
       "      <th>a/h</th>\n",
       "      <th>b/h</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>c1/a</th>\n",
       "      <th>c1/b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FS TV MAPE</th>\n",
       "      <td>4.342070</td>\n",
       "      <td>1.174272</td>\n",
       "      <td>7.153736</td>\n",
       "      <td>7.621831</td>\n",
       "      <td>3.004916</td>\n",
       "      <td>3.559428</td>\n",
       "      <td>3.237481</td>\n",
       "      <td>6.958819</td>\n",
       "      <td>6.833119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS TV SDAPE</th>\n",
       "      <td>5.492624</td>\n",
       "      <td>1.080555</td>\n",
       "      <td>6.423815</td>\n",
       "      <td>6.856258</td>\n",
       "      <td>2.211225</td>\n",
       "      <td>2.805035</td>\n",
       "      <td>2.731907</td>\n",
       "      <td>6.498789</td>\n",
       "      <td>6.224809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS Te MAPE</th>\n",
       "      <td>4.516578</td>\n",
       "      <td>1.196488</td>\n",
       "      <td>7.202018</td>\n",
       "      <td>7.682701</td>\n",
       "      <td>3.031508</td>\n",
       "      <td>3.619985</td>\n",
       "      <td>3.300656</td>\n",
       "      <td>7.028629</td>\n",
       "      <td>6.911643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS Te SDAPE</th>\n",
       "      <td>5.744519</td>\n",
       "      <td>1.103612</td>\n",
       "      <td>6.497174</td>\n",
       "      <td>6.925254</td>\n",
       "      <td>2.341376</td>\n",
       "      <td>2.956697</td>\n",
       "      <td>2.870681</td>\n",
       "      <td>6.615839</td>\n",
       "      <td>6.311143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS TV MAPE</th>\n",
       "      <td>5.487281</td>\n",
       "      <td>1.615551</td>\n",
       "      <td>10.447898</td>\n",
       "      <td>11.117207</td>\n",
       "      <td>3.526703</td>\n",
       "      <td>4.669190</td>\n",
       "      <td>4.326822</td>\n",
       "      <td>11.632629</td>\n",
       "      <td>11.436735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS TV SDAPE</th>\n",
       "      <td>6.795152</td>\n",
       "      <td>2.235379</td>\n",
       "      <td>11.595651</td>\n",
       "      <td>12.216842</td>\n",
       "      <td>3.899415</td>\n",
       "      <td>7.732041</td>\n",
       "      <td>6.960605</td>\n",
       "      <td>13.038216</td>\n",
       "      <td>12.850604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS Te MAPE</th>\n",
       "      <td>5.449303</td>\n",
       "      <td>1.601189</td>\n",
       "      <td>10.389290</td>\n",
       "      <td>11.040490</td>\n",
       "      <td>3.583306</td>\n",
       "      <td>4.633408</td>\n",
       "      <td>4.305861</td>\n",
       "      <td>11.609360</td>\n",
       "      <td>11.407006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS Te SDAPE</th>\n",
       "      <td>6.937029</td>\n",
       "      <td>2.268217</td>\n",
       "      <td>11.855520</td>\n",
       "      <td>12.363283</td>\n",
       "      <td>4.108009</td>\n",
       "      <td>7.918165</td>\n",
       "      <td>7.180219</td>\n",
       "      <td>13.282196</td>\n",
       "      <td>13.135407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   nu       a/b        a/h        b/h        Q2        Q3  \\\n",
       "FS TV MAPE   4.342070  1.174272   7.153736   7.621831  3.004916  3.559428   \n",
       "FS TV SDAPE  5.492624  1.080555   6.423815   6.856258  2.211225  2.805035   \n",
       "FS Te MAPE   4.516578  1.196488   7.202018   7.682701  3.031508  3.619985   \n",
       "FS Te SDAPE  5.744519  1.103612   6.497174   6.925254  2.341376  2.956697   \n",
       "RS TV MAPE   5.487281  1.615551  10.447898  11.117207  3.526703  4.669190   \n",
       "RS TV SDAPE  6.795152  2.235379  11.595651  12.216842  3.899415  7.732041   \n",
       "RS Te MAPE   5.449303  1.601189  10.389290  11.040490  3.583306  4.633408   \n",
       "RS Te SDAPE  6.937029  2.268217  11.855520  12.363283  4.108009  7.918165   \n",
       "\n",
       "                   Q4       c1/a       c1/b  \n",
       "FS TV MAPE   3.237481   6.958819   6.833119  \n",
       "FS TV SDAPE  2.731907   6.498789   6.224809  \n",
       "FS Te MAPE   3.300656   7.028629   6.911643  \n",
       "FS Te SDAPE  2.870681   6.615839   6.311143  \n",
       "RS TV MAPE   4.326822  11.632629  11.436735  \n",
       "RS TV SDAPE  6.960605  13.038216  12.850604  \n",
       "RS Te MAPE   4.305861  11.609360  11.407006  \n",
       "RS Te SDAPE  7.180219  13.282196  13.135407  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\myren\\My Drive\\University - BEng Mechanical\\4th Year\\MRN 412_422\\Revised Code\\ML_FFNN.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myren/My%20Drive/University%20-%20BEng%20Mechanical/4th%20Year/MRN%20412_422/Revised%20Code/ML_FFNN.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sfreq_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msf1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf3\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf4\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf5\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf6\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf7\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf8\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf9\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf10\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myren/My%20Drive/University%20-%20BEng%20Mechanical/4th%20Year/MRN%20412_422/Revised%20Code/ML_FFNN.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sfreq_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msf1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf3\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf4\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msf5\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/myren/My%20Drive/University%20-%20BEng%20Mechanical/4th%20Year/MRN%20412_422/Revised%20Code/ML_FFNN.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data[freq_name(num_freq,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)] \u001b[39m=\u001b[39m data[sfreq_list]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myren/My%20Drive/University%20-%20BEng%20Mechanical/4th%20Year/MRN%20412_422/Revised%20Code/ML_FFNN.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_freq):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myren/My%20Drive/University%20-%20BEng%20Mechanical/4th%20Year/MRN%20412_422/Revised%20Code/ML_FFNN.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     y \u001b[39m=\u001b[39m x\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\myren\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3643\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3641\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   3642\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[1;32m-> 3643\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[0;32m   3644\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   3645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\myren\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3685\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3680\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3681\u001b[0m     \u001b[39m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   3682\u001b[0m     \u001b[39m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   3684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3685\u001b[0m         check_key_length(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns, key, value)\n\u001b[0;32m   3686\u001b[0m         \u001b[39mfor\u001b[39;00m k1, k2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(key, value\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m   3687\u001b[0m             \u001b[39mself\u001b[39m[k1] \u001b[39m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\myren\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:428\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m columns\u001b[39m.\u001b[39mis_unique:\n\u001b[0;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(key):\n\u001b[1;32m--> 428\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    429\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m     \u001b[39m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(columns\u001b[39m.\u001b[39mget_indexer_non_unique(key)[\u001b[39m0\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# Predict Simulation Data of Experimental Plates\n",
    "data = pd.read_csv('Data Workspace/Experimental_Data.csv')\n",
    "sfreq_list = ['sf1','sf2','sf3','sf4','sf5','sf6','sf7','sf8','sf9','sf10']\n",
    "sfreq_list = ['sf1','sf2','sf3','sf4','sf5']\n",
    "data[freq_name(num_freq,1,0)] = data[sfreq_list]\n",
    "for x in range(num_freq):\n",
    "    y = x+1\n",
    "    for k in range(y-1):\n",
    "        l = k+1\n",
    "        ratio_str = 'f'+str(y)+'/f'+str(l)\n",
    "        data[ratio_str] = data['f'+str(y)] /data['f'+str(l)]\n",
    "\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "Exp_sim_X = X.to('cpu')\n",
    "Exp_sim_Y = Y.to('cpu')\n",
    "Exp_sim_predictY = predictY.to('cpu')\n",
    "\n",
    "Exp_sim_error = abs_perc_error.to('cpu')\n",
    "Exp_sim_error_mean = MAPE_per_dim.to('cpu')\n",
    "Exp_sim_error_std = SDAPE_per_dim.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.DataFrame(Exp_sim_error, columns = labels, index = ['Al-1','Al-2','Al-3','Al-4','Al-5','Al-6','St-1','St-2','St-3','St-4','St-5','St-6'])\n",
    "exp_df.to_excel('exp_sim_performance.xlsx', index=1)\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FS_Te_error_mean.mean())\n",
    "print(RS_Te_error_mean.mean())\n",
    "print(exp_df.mean().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(plot_labels, exp_df.mean(), exp_df.std(), marker='o', linestyle=':', capsize=5, capthick=2, color='blue')\n",
    "\n",
    "plt.ylim(-5,20)\n",
    "plt.ylabel('MAPE [%]')\n",
    "plt.xlabel('Plate Property')\n",
    "plt.title('FS - Train Validation Set ')\n",
    "plt.grid()\n",
    "plt.title('S-FFNN Error - Simulated Experimental Plates')\n",
    "plt.savefig('S_FFNN_error_plot_exp_sim.pdf',dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC_train = pd.read_csv(\"Current_ML_Results_Tensorboard_Batch Mean Loss_Train.csv\")\n",
    "LC_valid = pd.read_csv(\"Current_ML_Results_Tensorboard_Batch Mean Loss_Validation.csv\")\n",
    "\n",
    "plt.figure(figsize=(5,3.5))\n",
    "plt.semilogy(LC_train['Step'], LC_train['Value'])\n",
    "plt.semilogy(LC_valid['Step'], LC_valid['Value'])\n",
    "plt.title('S-FFNN Loss Curve')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid(axis='y', which='both')\n",
    "plt.xlim(-1,epochs+1)\n",
    "plt.ylim(0.005,0.2)\n",
    "# plt.yticks([0.1,0.125,0.15,0.175,0.2,0.225,0.25,0.275,0.3],[0.1,'',0.15,'',0.2,'',0.25,'',0.3])\n",
    "plt.savefig('S_FFNN_loss_curve.pdf', dpi=1200,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(12,12))\n",
    "\n",
    "prop_name = plot_labels[0]\n",
    "axes[0,0].set_title(prop_name)\n",
    "axes[0,0].set_ylabel('Predicted '+ prop_name)\n",
    "axes[0,0].set_xlabel('True '+ prop_name)\n",
    "axes[0,0].scatter(FS_Te_Y[:,0], FS_Te_predictY[:,0], s=1, color='salmon')\n",
    "axes[0,0].plot(np.linspace(FS_Te_Y[:,0].min(),FS_Te_Y[:,0].max(), 100),np.linspace(FS_Te_Y[:,0].min(),FS_Te_Y[:,0].max(), 100), 'k--')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[7]\n",
    "axes[1,0].set_title(prop_name)\n",
    "axes[1,0].set_ylabel('Predicted  '+ prop_name)\n",
    "axes[1,0].set_xlabel('True '+ prop_name)\n",
    "axes[1,0].scatter(FS_Te_Y[:,7], FS_Te_predictY[:,7], s=1, color='salmon')\n",
    "axes[1,0].plot(np.linspace(FS_Te_Y[:,7].min(),FS_Te_Y[:,7].max(), 100),np.linspace(FS_Te_Y[:,7].min(),FS_Te_Y[:,7].max(), 100), 'k--')\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[8]\n",
    "axes[2,0].set_title(prop_name)\n",
    "axes[2,0].set_ylabel('Predicted '+ prop_name)\n",
    "axes[2,0].set_xlabel('True '+ prop_name)\n",
    "axes[2,0].scatter(FS_Te_Y[:,8], FS_Te_predictY[:,8], s=1, color='salmon')\n",
    "axes[2,0].plot(np.linspace(FS_Te_Y[:,8].min(),FS_Te_Y[:,8].max(), 100),np.linspace(FS_Te_Y[:,8].min(),FS_Te_Y[:,8].max(), 100), 'k--')\n",
    "axes[2,0].set_xscale('log')\n",
    "axes[2,0].set_yscale('log')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[1]\n",
    "axes[0,1].set_title(prop_name)\n",
    "axes[0,1].set_ylabel('Predicted '+ prop_name)\n",
    "axes[0,1].set_xlabel('True '+ prop_name)\n",
    "axes[0,1].scatter(FS_Te_Y[:,1], FS_Te_predictY[:,1], s=1, color='salmon')\n",
    "axes[0,1].plot(np.linspace(FS_Te_Y[:,1].min(),FS_Te_Y[:,1].max(), 100),np.linspace(FS_Te_Y[:,1].min(),FS_Te_Y[:,1].max(), 100), 'k--')\n",
    "axes[0,1].set_yticks([1,1.5,2,2.5,3,3.5,4],[1,1.5,2,2.5,3,3.5,4])\n",
    "\n",
    "\n",
    "prop_name = plot_labels[2]\n",
    "axes[1,1].set_title(prop_name)\n",
    "axes[1,1].set_ylabel('Predicted '+ prop_name)\n",
    "axes[1,1].set_xlabel('True '+ prop_name)\n",
    "axes[1,1].scatter(FS_Te_Y[:,2], FS_Te_predictY[:,2], s=1, color='salmon')\n",
    "axes[1,1].plot(np.linspace(FS_Te_Y[:,2].min(),FS_Te_Y[:,2].max(), 100),np.linspace(FS_Te_Y[:,2].min(),FS_Te_Y[:,2].max(), 100), 'k--')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[3]\n",
    "axes[2,1].set_title(prop_name)\n",
    "axes[2,1].set_ylabel('Predicted '+ prop_name)\n",
    "axes[2,1].set_xlabel('True '+ prop_name)\n",
    "axes[2,1].scatter(FS_Te_Y[:,3], FS_Te_predictY[:,3], s=1, color='salmon')\n",
    "axes[2,1].plot(np.linspace(FS_Te_Y[:,3].min(),FS_Te_Y[:,3].max(), 100),np.linspace(FS_Te_Y[:,3].min(),FS_Te_Y[:,3].max(), 100), 'k--')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[4]\n",
    "axes[0,2].set_title(prop_name)\n",
    "axes[0,2].set_ylabel('Predicted '+ prop_name)\n",
    "axes[0,2].set_xlabel('True '+ prop_name)\n",
    "axes[0,2].scatter(FS_Te_Y[:,4], FS_Te_predictY[:,4], s=1, color='salmon')\n",
    "axes[0,2].plot(np.linspace(FS_Te_Y[:,4].min(),FS_Te_Y[:,4].max(), 100),np.linspace(FS_Te_Y[:,4].min(),FS_Te_Y[:,4].max(), 100), 'k--')\n",
    "axes[0,2].set_xscale('log')\n",
    "axes[0,2].set_yscale('log')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[5]\n",
    "axes[1,2].set_title(prop_name)\n",
    "axes[1,2].set_ylabel('Predicted '+ prop_name)\n",
    "axes[1,2].set_xlabel('True '+ prop_name)\n",
    "axes[1,2].scatter(FS_Te_Y[:,5], FS_Te_predictY[:,5], s=1, color='salmon')\n",
    "axes[1,2].plot(np.linspace(FS_Te_Y[:,5].min(),FS_Te_Y[:,5].max(), 100),np.linspace(FS_Te_Y[:,5].min(),FS_Te_Y[:,5].max(), 100), 'k--')\n",
    "axes[1,2].set_xscale('log')\n",
    "axes[1,2].set_yscale('log')\n",
    "\n",
    "\n",
    "prop_name = plot_labels[6]\n",
    "axes[2,2].set_title(prop_name)\n",
    "axes[2,2].set_ylabel('Predicted '+ prop_name)\n",
    "axes[2,2].set_xlabel('True '+ prop_name)\n",
    "axes[2,2].scatter(FS_Te_Y[:,6], FS_Te_predictY[:,6], s=1, color='salmon')\n",
    "axes[2,2].plot(np.linspace(FS_Te_Y[:,6].min(),FS_Te_Y[:,6].max(), 100),np.linspace(FS_Te_Y[:,6].min(),FS_Te_Y[:,6].max(), 100), 'k--')\n",
    "axes[2,2].set_xscale('log')\n",
    "axes[2,2].set_yscale('log')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.425, wspace=0.425, top=0.925)\n",
    "fig.suptitle('S-FFNN Predictions vs True Properties',fontsize=14)\n",
    "plt.savefig('S_FFNN_predict_true.pdf',dpi=1200,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,4))\n",
    "# plt.errorbar(plot_labels, exp_df.mean(), exp_df.std(), marker='o', linestyle=':', capsize=5, capthick=2, color='blue')\n",
    "# plt.ylim(-5,50)\n",
    "# plt.ylabel('MAPE [%]')\n",
    "# plt.xlabel('Plate Property')\n",
    "# plt.grid()\n",
    "# plt.title('S-FFNN 5 Frequency Error - Simulated Experimental Plates')\n",
    "# plt.savefig('5freq_S_FFNN_error_plot_exp_sim.pdf',dpi=1200, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.errorbar(plot_labels, RS_Te_error_mean, RS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='green')\n",
    "# plt.ylim(-5,50)\n",
    "# plt.ylabel('MAPE [%]')\n",
    "# plt.xlabel('Plate Property')\n",
    "# plt.grid()\n",
    "# plt.title('S-FFNN 5 Frequency Error - RS Test Set')\n",
    "# plt.savefig('5freq_S_FFNN_error_plot_RS.pdf',dpi=1200, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.errorbar(plot_labels, FS_Te_error_mean, FS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='red')\n",
    "# plt.ylim(-5,50)\n",
    "# plt.ylabel('MAPE [%]')\n",
    "# plt.xlabel('Plate Property')\n",
    "# plt.grid()\n",
    "# plt.title('S-FFNN 5 Frequency Error - FS Test Set')\n",
    "# plt.savefig('5freq_S_FFNN_error_plot_FS.pdf',dpi=1200, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(plot_labels, exp_df.mean(), exp_df.std(), marker='o', linestyle=':', capsize=5, capthick=2, color='blue')\n",
    "plt.ylim(-5,50)\n",
    "plt.ylabel('MAPE [%]')\n",
    "plt.xlabel('Plate Property')\n",
    "plt.grid()\n",
    "plt.title('S-FFNN 8 Frequency Error - Simulated Experimental Plates')\n",
    "plt.savefig('8freq_S_FFNN_error_plot_exp_sim.pdf',dpi=1200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(plot_labels, RS_Te_error_mean, RS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='green')\n",
    "plt.ylim(-5,50)\n",
    "plt.ylabel('MAPE [%]')\n",
    "plt.xlabel('Plate Property')\n",
    "plt.grid()\n",
    "plt.title('S-FFNN 8 Frequency Error - RS Test Set')\n",
    "plt.savefig('8freq_S_FFNN_error_plot_RS.pdf',dpi=1200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(plot_labels, FS_Te_error_mean, FS_Te_error_std, marker='o', linestyle=':', capsize=5, capthick=2, color='red')\n",
    "plt.ylim(-5,50)\n",
    "plt.ylabel('MAPE [%]')\n",
    "plt.xlabel('Plate Property')\n",
    "plt.grid()\n",
    "plt.title('S-FFNN 8 Frequency Error - FS Test Set')\n",
    "plt.savefig('8freq_S_FFNN_error_plot_FS.pdf',dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Simulation Data of Experimental Plates\n",
    "data = pd.read_csv('Data Workspace/Experimental_Data_Freq8.csv')\n",
    "\n",
    "sfreq_list = ['ef1','ef2','ef3','ef4','ef5', 'ef6', 'ef7', 'ef8']\n",
    "data[freq_name(num_freq,1,0)] = data[sfreq_list]\n",
    "for x in range(num_freq):\n",
    "    y = x+1\n",
    "    for k in range(y-1):\n",
    "        l = k+1\n",
    "        ratio_str = 'f'+str(y)+'/f'+str(l)\n",
    "        data[ratio_str] = data['f'+str(y)] /data['f'+str(l)]\n",
    "\n",
    "scaled_data = data[features+labels].copy()\n",
    "\n",
    "scaled_data[freq_name(num_freq,1,0)] = np.log(scaled_data[freq_name(num_freq,1,0)])\n",
    "scaled_data[labels[-5:]] = np.log(scaled_data[labels[-5:]])\n",
    "\n",
    "scaled_data = FFNN_data(scalerX.transform(scaled_data[features]), scalerY.transform(scaled_data[labels]))\n",
    "data_loader = to.utils.data.DataLoader(scaled_data, batch_size=len(scaled_data), shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with to.no_grad():\n",
    "    for i, data in enumerate(data_loader):\n",
    "        X, Y = data\n",
    "        predictY = model.feedfoward(X)\n",
    "\n",
    "        X = scalerX.inverse_transform(X.to('cpu'))\n",
    "        Y = scalerY.inverse_transform(Y.to('cpu'))\n",
    "        predictY = scalerY.inverse_transform(predictY.to('cpu'))\n",
    "\n",
    "        X = to.from_numpy(X).to(device)\n",
    "        Y = to.from_numpy(Y).to(device)\n",
    "        predictY = to.from_numpy(predictY).to(device)\n",
    "\n",
    "        Y[:,-5:] = to.exp(Y[:,-5:])\n",
    "        predictY[:,-5:] = to.exp(predictY[:,-5:])\n",
    "            \n",
    "        abs_perc_error = to.abs((Y- predictY)/Y)*100\n",
    "        MAPE_per_dim = to.mean(abs_perc_error, 0)\n",
    "        SDAPE_per_dim = to.std(abs_perc_error, 0)\n",
    "\n",
    "Exp_sim_X = X.to('cpu')\n",
    "Exp_sim_Y = Y.to('cpu')\n",
    "Exp_sim_predictY = predictY.to('cpu')\n",
    "\n",
    "Exp_sim_error = abs_perc_error.to('cpu')\n",
    "Exp_sim_error_mean = MAPE_per_dim.to('cpu')\n",
    "Exp_sim_error_std = SDAPE_per_dim.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nu</th>\n",
       "      <th>a/b</th>\n",
       "      <th>a/h</th>\n",
       "      <th>b/h</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>c1/a</th>\n",
       "      <th>c1/b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Al-1</th>\n",
       "      <td>20.646171</td>\n",
       "      <td>0.890614</td>\n",
       "      <td>12.755469</td>\n",
       "      <td>13.076222</td>\n",
       "      <td>1.624898</td>\n",
       "      <td>2.074255</td>\n",
       "      <td>1.395005</td>\n",
       "      <td>19.972154</td>\n",
       "      <td>19.421872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al-6</th>\n",
       "      <td>23.252112</td>\n",
       "      <td>4.906089</td>\n",
       "      <td>47.036879</td>\n",
       "      <td>43.364885</td>\n",
       "      <td>2.406092</td>\n",
       "      <td>3.892167</td>\n",
       "      <td>5.479685</td>\n",
       "      <td>40.556097</td>\n",
       "      <td>43.495968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-1</th>\n",
       "      <td>28.710498</td>\n",
       "      <td>1.829914</td>\n",
       "      <td>45.814681</td>\n",
       "      <td>46.392303</td>\n",
       "      <td>1.468373</td>\n",
       "      <td>2.012057</td>\n",
       "      <td>2.847097</td>\n",
       "      <td>45.013129</td>\n",
       "      <td>44.776568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-2</th>\n",
       "      <td>39.379391</td>\n",
       "      <td>20.385942</td>\n",
       "      <td>33.402575</td>\n",
       "      <td>42.143976</td>\n",
       "      <td>25.494351</td>\n",
       "      <td>2.409342</td>\n",
       "      <td>10.927091</td>\n",
       "      <td>50.613493</td>\n",
       "      <td>41.848377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-3</th>\n",
       "      <td>27.988087</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>60.695318</td>\n",
       "      <td>59.213750</td>\n",
       "      <td>1.816170</td>\n",
       "      <td>0.923561</td>\n",
       "      <td>2.401531</td>\n",
       "      <td>57.905986</td>\n",
       "      <td>58.567550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-4</th>\n",
       "      <td>35.721330</td>\n",
       "      <td>13.591640</td>\n",
       "      <td>43.514023</td>\n",
       "      <td>49.047431</td>\n",
       "      <td>14.817497</td>\n",
       "      <td>6.754734</td>\n",
       "      <td>3.856220</td>\n",
       "      <td>51.734148</td>\n",
       "      <td>45.686497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-5</th>\n",
       "      <td>31.478369</td>\n",
       "      <td>0.276952</td>\n",
       "      <td>40.632496</td>\n",
       "      <td>40.233151</td>\n",
       "      <td>0.568956</td>\n",
       "      <td>1.601227</td>\n",
       "      <td>0.964577</td>\n",
       "      <td>40.950599</td>\n",
       "      <td>41.076447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-6</th>\n",
       "      <td>38.235003</td>\n",
       "      <td>10.189729</td>\n",
       "      <td>50.464418</td>\n",
       "      <td>53.790812</td>\n",
       "      <td>8.804615</td>\n",
       "      <td>7.919464</td>\n",
       "      <td>1.247950</td>\n",
       "      <td>54.481024</td>\n",
       "      <td>50.123512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nu        a/b        a/h        b/h         Q2        Q3  \\\n",
       "Al-1  20.646171   0.890614  12.755469  13.076222   1.624898  2.074255   \n",
       "Al-6  23.252112   4.906089  47.036879  43.364885   2.406092  3.892167   \n",
       "St-1  28.710498   1.829914  45.814681  46.392303   1.468373  2.012057   \n",
       "St-2  39.379391  20.385942  33.402575  42.143976  25.494351  2.409342   \n",
       "St-3  27.988087   0.002425  60.695318  59.213750   1.816170  0.923561   \n",
       "St-4  35.721330  13.591640  43.514023  49.047431  14.817497  6.754734   \n",
       "St-5  31.478369   0.276952  40.632496  40.233151   0.568956  1.601227   \n",
       "St-6  38.235003  10.189729  50.464418  53.790812   8.804615  7.919464   \n",
       "\n",
       "             Q4       c1/a       c1/b  \n",
       "Al-1   1.395005  19.972154  19.421872  \n",
       "Al-6   5.479685  40.556097  43.495968  \n",
       "St-1   2.847097  45.013129  44.776568  \n",
       "St-2  10.927091  50.613493  41.848377  \n",
       "St-3   2.401531  57.905986  58.567550  \n",
       "St-4   3.856220  51.734148  45.686497  \n",
       "St-5   0.964577  40.950599  41.076447  \n",
       "St-6   1.247950  54.481024  50.123512  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df8 = pd.DataFrame(Exp_sim_error, columns = labels, index = ['Al-1','Al-2','Al-3','Al-4','Al-5','Al-6','St-1','St-2','St-3','St-4','St-5','St-6'])\n",
    "exp_df8.to_excel('exp_sim_performance_freq8.xlsx', index=1)\n",
    "exp_df8.iloc[[0,5,6,7,8,9,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df8.iloc[[0,5,6,7,8,9,10,11]].to_csv('8freq_perf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nu      30.676370\n",
       "a/b      6.509163\n",
       "a/h     41.789482\n",
       "b/h     43.407816\n",
       "Q2       7.125119\n",
       "Q3       3.448351\n",
       "Q4       3.639894\n",
       "c1/a    45.153329\n",
       "c1/b    43.124599\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df8.iloc[[0,5,6,7,8,9,10,11]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 model\n",
    "# AL 2 3 4 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2426e189533ac41f5aad4fbc5dc1b573401ba6ae3fed99d7f2363912ea400c87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
